{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Currently Loaded Modules:\n",
      "  1) anaconda3/5.1.0-gcc/8.3.1     4) cudnn/8.0.0.180-11.0-linux-x64-gcc/7.5.0\n",
      "  2) anaconda3/2019.10-gcc/8.3.1   5) openjdk/1.8.0_222-b10-gcc/8.3.1\n",
      "  3) cuda/11.0.3-gcc/7.5.0         6) hadoop/3.2.1-gcc/8.3.1\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!module list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Flatten, TimeDistributed, Dropout, LSTMCell, RNN, Bidirectional, Concatenate, Layer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import requests\n",
    "import tarfile\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Project_CodeNet_LangClass.tar.gz\"\n",
    "data_url = f\"https://dax-cdn.cdn.appdomain.cloud/dax-project-codenet/1.0.0/{file_name}\"\n",
    "\n",
    "# Download tar archive to local disk\n",
    "with open(file_name, \"wb\") as f:\n",
    "    f.write(requests.get(data_url).content)\n",
    "    \n",
    "# Extract contents of archive to local disk\n",
    "if os.path.exists(\"data\"):\n",
    "    shutil.rmtree(\"data\")    \n",
    "with tarfile.open(file_name) as tfile:\n",
    "    tfile.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "test  train\n",
      "\n",
      "data/train:\n",
      "C  C#  C++  D  Haskell\tJava  JavaScript  PHP  Python  Rust\n"
     ]
    }
   ],
   "source": [
    "!ls data data/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [\n",
    "  \"C\",\n",
    "  \"C#\",\n",
    "  \"C++\",\n",
    "  \"D\",\n",
    "  \"Haskell\",\n",
    "  \"Java\",\n",
    "  \"JavaScript\",\n",
    "  \"PHP\",\n",
    "  \"Python\",\n",
    "  \"Rust\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import re\n",
    "from tokenize import tokenize, untokenize, COMMENT, STRING, NEWLINE, ENCODING, ENDMARKER, NL, INDENT, NUMBER\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "lits = json.load(open(\"literals.json\"))\n",
    "\n",
    "def process_string(token, special_chars={\" \": \"U+0020\", \",\": \"U+002C\"}):\n",
    "    str_quote_options = [\"'''\", '\"\"\"', \"'\", '\"']\n",
    "    start_quote = \"\"\n",
    "    end_quote = \"\"\n",
    "    qualifier_regex = r\"^[a-z]+\"\n",
    "    qualifier_match = re.search(qualifier_regex, token)\n",
    "    # string qualifiers like 'r' for regex, 'f' for formatted string, 'b' for bytes, 'u' for unicode, etc (or combination of them)\n",
    "    qualifier = \"\" if not qualifier_match else qualifier_match[0]\n",
    "    # token string without qualifiers\n",
    "    token_string = re.sub(qualifier_regex, \"\", token)\n",
    "    # string literal without quotes\n",
    "    str_lit = token_string\n",
    "    for q in str_quote_options:\n",
    "        if token_string.startswith(q):\n",
    "            start_quote = q\n",
    "            str_lit = str_lit[len(q) :]\n",
    "            if token_string.endswith(q):\n",
    "                end_quote = q\n",
    "                str_lit = str_lit[: -len(q)]\n",
    "            break\n",
    "    # if start_quote in str_quote_options[:2]:\n",
    "    #     return \"\"\n",
    "    for sc in special_chars:\n",
    "        str_lit = str_lit.replace(sc, special_chars[sc])\n",
    "    return (\n",
    "        f\"{qualifier}{start_quote}<STR_LIT:{str_lit}>{end_quote}\"\n",
    "        if str_lit in lits['str']\n",
    "        else f\"{qualifier}{start_quote}<STR_LIT>{end_quote}\"\n",
    "    )\n",
    "\n",
    "def py_tokenize(args, file_name, file_type):\n",
    "    file_paths = open(os.path.join(args.base_dir, file_name)).readlines()\n",
    "    wf = open(os.path.join(args.output_dir, f\"{file_type}.txt\"), 'w')\n",
    "    for ct,path in enumerate(file_paths):\n",
    "        try:\n",
    "            code = open(os.path.join(args.base_dir, path.strip())).read()\n",
    "            token_gen = tokenize(BytesIO(bytes(code, \"utf8\")).readline)\n",
    "            out_tokens = []\n",
    "            prev_eol = False\n",
    "            for toknum, tokval, _, _, _ in token_gen:\n",
    "                tokval = \" \".join(tokval.split())\n",
    "                if toknum == STRING:\n",
    "                    add_token = process_string(tokval)\n",
    "                    out_tokens.append(add_token)\n",
    "                    prev_eol = False\n",
    "                elif toknum == NUMBER:\n",
    "                    if tokval in lits['num']:\n",
    "                        out_tokens.append(f\"<NUM_LIT:{tokval}>\")\n",
    "                    else:\n",
    "                        out_tokens.append(f\"<NUM_LIT>\")\n",
    "                    prev_eol = False\n",
    "                elif toknum in [NEWLINE, NL]:\n",
    "                    if not prev_eol:\n",
    "                        out_tokens.append(\"<EOL>\")\n",
    "                        prev_eol = True\n",
    "                elif toknum in [COMMENT, INDENT, ENCODING, ENDMARKER] or len(tokval) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    out_tokens.append(tokval)\n",
    "                    prev_eol = False\n",
    "            if out_tokens[0] == \"<EOL>\":\n",
    "                out_tokens = out_tokens[1:]\n",
    "            if out_tokens[-1] == \"<EOL>\":\n",
    "                out_tokens = out_tokens[:-1]\n",
    "        except Exception:\n",
    "            out_tokens = []\n",
    "        out_tokens = [\"<s>\"] + out_tokens + [\"</s>\"]\n",
    "        out = \" \".join(out_tokens)\n",
    "        wf.write(out+\"\\n\")\n",
    "\n",
    "        if ct % 10000 == 0:\n",
    "            print(f\"{file_type}: {ct} are done\")\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['answermap[1] = 4\\n', 'answermap[2] = 10\\n', 'answermap[3] = 20\\n', 'answermap[4] = 35\\n', 'answermap[5] = 56\\n', 'answermap[6] = 84\\n', 'answermap[7] = 120\\n', 'answermap[8] = 165\\n', 'answermap[9] = 220\\n', 'answermap[10] = 282\\n']\n"
     ]
    }
   ],
   "source": [
    "file_list = glob.glob(os.path.join(os.getcwd(),\"data/train/Python\",\"*.*\"))\n",
    "corpus = []\n",
    "\n",
    "for file_path in file_list:\n",
    "    with open(file_path) as f_input:\n",
    "        corpus.extend([line for line in f_input])\n",
    "        \n",
    "print(corpus[40:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(): \n",
    "    output = []\n",
    "    for line in corpus:\n",
    "        token_list = line\n",
    "        for i in range(1, len(token_list)):\n",
    "            data = []\n",
    "            x_ngram = '<start> '+ token_list[:i+1] + ' <end>'\n",
    "            y_ngram = '<start> '+ token_list[i+1:] + ' <end>'\n",
    "            data.append(x_ngram)\n",
    "            data.append(y_ngram)\n",
    "            output.append(data)\n",
    "    print(\"Dataset prepared with prefix and suffixes for teacher forcing technique\")\n",
    "    dummy_df = pd.DataFrame(output, columns=['input','output'])\n",
    "    return output, dummy_df     \n",
    "\n",
    "class LanguageIndex():\n",
    "    def __init__(self, lang):\n",
    "        self.lang = lang\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab = set()\n",
    "        self.create_index()\n",
    "    def create_index(self):\n",
    "        for phrase in self.lang:\n",
    "            self.vocab.update(phrase.split(' '))\n",
    "        self.vocab = sorted(self.vocab)\n",
    "        self.word2idx[\"<pad>\"] = 0\n",
    "        self.idx2word[0] = \"<pad>\"\n",
    "        for i,word in enumerate(self.vocab):\n",
    "            self.word2idx[word] = i + 1\n",
    "            self.idx2word[i+1] = word\n",
    "\n",
    "def max_length(t):\n",
    "    return max(len(i) for i in t)\n",
    "\n",
    "def load_dataset():\n",
    "    pairs,df = generate_dataset()\n",
    "    out_lang = LanguageIndex(sp for en, sp in pairs)\n",
    "    in_lang = LanguageIndex(en for en, sp in pairs)\n",
    "    input_data = [[in_lang.word2idx[s] for s in en.split(' ')] for en, sp in pairs]\n",
    "    output_data = [[out_lang.word2idx[s] for s in sp.split(' ')] for en, sp in pairs]\n",
    "\n",
    "    max_length_in, max_length_out = max_length(input_data), max_length(output_data)\n",
    "    input_data = tf.keras.preprocessing.sequence.pad_sequences(input_data, maxlen=max_length_in, padding=\"post\")\n",
    "    output_data = tf.keras.preprocessing.sequence.pad_sequences(output_data, maxlen=max_length_out, padding=\"post\")\n",
    "    return input_data, output_data, in_lang, out_lang, max_length_in, max_length_out, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset prepared with prefix and suffixes for teacher forcing technique\n"
     ]
    }
   ],
   "source": [
    "input_data, teacher_data, input_lang, target_lang, len_input, len_target, df = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = [[teacher_data[n][i+1] for i in range(len(teacher_data[n])-1)] for n in range(len(teacher_data))]\n",
    "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, maxlen=len_target, padding=\"post\")\n",
    "target_data = target_data.reshape((target_data.shape[0], target_data.shape[1], 1))\n",
    "\n",
    "# Shuffle all of the data in unison. This training set has the longest (e.g. most complicated) data at the end,\n",
    "# so a simple Keras validation split will be problematic if not shuffled.\n",
    "\n",
    "p = np.random.permutation(len(input_data))\n",
    "input_data = input_data[p]\n",
    "teacher_data = teacher_data[p]\n",
    "target_data = target_data[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>124023</td>\n",
       "      <td>124023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>57347</td>\n",
       "      <td>63763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>&lt;start&gt;    &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt;  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>3254</td>\n",
       "      <td>4424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   input          output\n",
       "count   124023            124023        \n",
       "unique  57347             63763         \n",
       "top     <start>    <end>  <start>  <end>\n",
       "freq    3254              4424          "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "BUFFER_SIZE = len(input_data)\n",
    "BATCH_SIZE = 128\n",
    "embedding_dim = 300\n",
    "units = 128\n",
    "vocab_in_size = len(input_lang.word2idx)\n",
    "vocab_out_size = len(target_lang.word2idx)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 231)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 231, 300)     6453600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 231, 256), ( 439296      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    7553100     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           bidirectional[0][1]              \n",
      "                                                                 bidirectional[0][3]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional[0][3]              \n",
      "                                                                 bidirectional[0][4]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  570368      embedding_1[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 256)    0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 128)    32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 128)    0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 25177)  3247833     dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 18,297,093\n",
      "Trainable params: 18,297,093\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Encoder layers first.\n",
    "encoder_inputs = Input(shape=(len_input,))\n",
    "encoder_emb = Embedding(input_dim=vocab_in_size, output_dim=embedding_dim)\n",
    "\n",
    "# Use this if you dont need Bidirectional LSTM\n",
    "# encoder_lstm = CuDNNLSTM(units=units, return_sequences=True, return_state=True)\n",
    "# encoder_out, state_h, state_c = encoder_lstm(encoder_emb(encoder_inputs))\n",
    "\n",
    "encoder_lstm = Bidirectional(LSTM(units=units, return_sequences=True, return_state=True))\n",
    "encoder_out, fstate_h, fstate_c, bstate_h, bstate_c = encoder_lstm(encoder_emb(encoder_inputs))\n",
    "state_h = Concatenate()([fstate_h,bstate_h])\n",
    "state_c = Concatenate()([bstate_h,bstate_c])\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "# Now create the Decoder layers.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_emb = Embedding(input_dim=vocab_out_size, output_dim=embedding_dim)\n",
    "decoder_lstm = LSTM(units=units*2, return_sequences=True, return_state=True)\n",
    "decoder_lstm_out, _, _ = decoder_lstm(decoder_emb(decoder_inputs), initial_state=encoder_states)\n",
    "# Two dense layers added to this model to improve inference capabilities.\n",
    "decoder_d1 = Dense(units, activation=\"relu\")\n",
    "decoder_d2 = Dense(vocab_out_size, activation=\"softmax\")\n",
    "decoder_out = decoder_d2(Dropout(rate=.2)(decoder_d1(Dropout(rate=.2)(decoder_lstm_out))))\n",
    "\n",
    "\n",
    "# Finally, create a training model which combines the encoder and the decoder.\n",
    "# Note that this model has three inputs:\n",
    "model = Model(inputs = [encoder_inputs, decoder_inputs], outputs= decoder_out)\n",
    "\n",
    "# We'll use sparse_categorical_crossentropy so we don't have to expand decoder_out into a massive one-hot array.\n",
    "# Adam is used because it's, well, the best.\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\", metrics=['sparse_categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "776/776 [==============================] - 1568s 2s/step - loss: 0.1196 - sparse_categorical_accuracy: 0.9839 - val_loss: 0.0873 - val_sparse_categorical_accuracy: 0.9873\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.11961, saving model to model.h5\n",
      "Epoch 2/10\n",
      "776/776 [==============================] - 1599s 2s/step - loss: 0.0771 - sparse_categorical_accuracy: 0.9884 - val_loss: 0.0649 - val_sparse_categorical_accuracy: 0.9904\n",
      "\n",
      "Epoch 00002: loss improved from 0.11961 to 0.07710, saving model to model.h5\n",
      "Epoch 3/10\n",
      "776/776 [==============================] - 1566s 2s/step - loss: 0.0612 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.0546 - val_sparse_categorical_accuracy: 0.9916\n",
      "\n",
      "Epoch 00003: loss improved from 0.07710 to 0.06120, saving model to model.h5\n",
      "Epoch 4/10\n",
      "776/776 [==============================] - 1564s 2s/step - loss: 0.0517 - sparse_categorical_accuracy: 0.9916 - val_loss: 0.0479 - val_sparse_categorical_accuracy: 0.9924\n",
      "\n",
      "Epoch 00004: loss improved from 0.06120 to 0.05169, saving model to model.h5\n",
      "Epoch 5/10\n",
      "776/776 [==============================] - 1572s 2s/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0434 - val_sparse_categorical_accuracy: 0.9932\n",
      "\n",
      "Epoch 00005: loss improved from 0.05169 to 0.04456, saving model to model.h5\n",
      "Epoch 6/10\n",
      "776/776 [==============================] - 1608s 2s/step - loss: 0.0395 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0404 - val_sparse_categorical_accuracy: 0.9936\n",
      "\n",
      "Epoch 00006: loss improved from 0.04456 to 0.03945, saving model to model.h5\n",
      "Epoch 7/10\n",
      "776/776 [==============================] - 1586s 2s/step - loss: 0.0354 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0390 - val_sparse_categorical_accuracy: 0.9939\n",
      "\n",
      "Epoch 00007: loss improved from 0.03945 to 0.03542, saving model to model.h5\n",
      "Epoch 8/10\n",
      "776/776 [==============================] - 1583s 2s/step - loss: 0.0319 - sparse_categorical_accuracy: 0.9943 - val_loss: 0.0365 - val_sparse_categorical_accuracy: 0.9942\n",
      "\n",
      "Epoch 00008: loss improved from 0.03542 to 0.03186, saving model to model.h5\n",
      "Epoch 9/10\n",
      "776/776 [==============================] - 1588s 2s/step - loss: 0.0287 - sparse_categorical_accuracy: 0.9946 - val_loss: 0.0350 - val_sparse_categorical_accuracy: 0.9945\n",
      "\n",
      "Epoch 00009: loss improved from 0.03186 to 0.02871, saving model to model.h5\n",
      "Epoch 10/10\n",
      "776/776 [==============================] - 1626s 2s/step - loss: 0.0261 - sparse_categorical_accuracy: 0.9950 - val_loss: 0.0339 - val_sparse_categorical_accuracy: 0.9947\n",
      "\n",
      "Epoch 00010: loss improved from 0.02871 to 0.02611, saving model to model.h5\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "history = model.fit([input_data, teacher_data], target_data,\n",
    "                 batch_size= BATCH_SIZE,\n",
    "                 epochs=epochs,\n",
    "                 validation_split=0.2,\n",
    "                 callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results of the training.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the encoder model from the tensors we previously declared.\n",
    "encoder_model = Model(encoder_inputs, [encoder_out, state_h, state_c])\n",
    "\n",
    "# Generate a new set of tensors for our new inference decoder. Note that we are using new tensors, \n",
    "# this does not preclude using the same underlying layers that we trained on. (e.g. weights/biases).\n",
    "\n",
    "inf_decoder_inputs = Input(shape=(None,), name=\"inf_decoder_inputs\")\n",
    "# We'll need to force feed the two state variables into the decoder each step.\n",
    "state_input_h = Input(shape=(units*2,), name=\"state_input_h\")\n",
    "state_input_c = Input(shape=(units*2,), name=\"state_input_c\")\n",
    "decoder_res, decoder_h, decoder_c = decoder_lstm(\n",
    "    decoder_emb(inf_decoder_inputs), \n",
    "    initial_state=[state_input_h, state_input_c])\n",
    "inf_decoder_out = decoder_d2(decoder_d1(decoder_res))\n",
    "inf_model = Model(inputs=[inf_decoder_inputs, state_input_h, state_input_c], \n",
    "                  outputs=[inf_decoder_out, decoder_h, decoder_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the given sentence (just a string) into a vector of word IDs\n",
    "# Output is 1-D: [timesteps/words]\n",
    "\n",
    "def sentence_to_vector(sentence, lang):\n",
    "\n",
    "    pre = sentence\n",
    "    vec = np.zeros(len_input)\n",
    "    sentence_list = [lang.word2idx[s] for s in pre.split(' ')]\n",
    "    for i,w in enumerate(sentence_list):\n",
    "        vec[i] = w\n",
    "    return vec\n",
    "\n",
    "# Given an input string, an encoder model (infenc_model) and a decoder model (infmodel),\n",
    "def translate(input_sentence, infenc_model, infmodel):\n",
    "    sv = sentence_to_vector(input_sentence, input_lang)\n",
    "    sv = sv.reshape(1,len(sv))\n",
    "    [emb_out, sh, sc] = infenc_model.predict(x=sv)\n",
    "    \n",
    "    i = 0\n",
    "    start_vec = target_lang.word2idx[\"<start>\"]\n",
    "    stop_vec = target_lang.word2idx[\"<end>\"]\n",
    "    \n",
    "    cur_vec = np.zeros((1,1))\n",
    "    cur_vec[0,0] = start_vec\n",
    "    cur_word = \"<start>\"\n",
    "    output_sentence = \"\"\n",
    "\n",
    "    while cur_word != \"<end>\" and i < (len_target-1):\n",
    "        i += 1\n",
    "        if cur_word != \"<start>\":\n",
    "            output_sentence = output_sentence + \" \" + cur_word\n",
    "        x_in = [cur_vec, sh, sc]\n",
    "        [nvec, sh, sc] = infmodel.predict(x=x_in)\n",
    "        cur_vec[0,0] = np.argmax(nvec[0,0])\n",
    "        cur_word = target_lang.idx2word[np.argmax(nvec[0,0])]\n",
    "    return output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input seq</th>\n",
       "      <th>Pred. Seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>for</td>\n",
       "      <td>the Sample Input\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>for i in range</td>\n",
       "      <td>(n):\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>if</td>\n",
       "      <td>import bisect_left\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>import</td>\n",
       "      <td>v2: list)-&gt;float:\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>import math</td>\n",
       "      <td>utf-8 -*-\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>import ma</td>\n",
       "      <td>}\".format(R*R*math.pi,R*2*math.pi))\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Input seq                               Pred. Seq\n",
       "0  for               the Sample Input\\n                  \n",
       "1  for i in range   (n):\\n                               \n",
       "2  if               import bisect_left\\n                 \n",
       "3  import            v2: list)->float:\\n                 \n",
       "4  import math       utf-8 -*-\\n                         \n",
       "5  import ma        }\".format(R*R*math.pi,R*2*math.pi))\\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\n",
    "    'for',\n",
    "    'for i in range',\n",
    "    'if',\n",
    "    'import ',\n",
    "    'import math',\n",
    "    'import ma'\n",
    "]\n",
    "  \n",
    "\n",
    "import pandas as pd\n",
    "output = []  \n",
    "for t in test:  \n",
    "  output.append({\"Input seq\":t.lower(), \"Pred. Seq\":translate(t.lower(), encoder_model, inf_model)})\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(output) \n",
    "results_df.head(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorflowGPU",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
