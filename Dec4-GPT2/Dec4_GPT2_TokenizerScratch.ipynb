{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Flatten, TimeDistributed, Dropout, LSTMCell, RNN, Bidirectional, Concatenate, Layer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import pickle\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import requests\n",
    "import tarfile\n",
    "import glob\n",
    "\n",
    "import argparse\n",
    "from tokenize import tokenize, untokenize, COMMENT, STRING, NEWLINE, ENCODING, ENDMARKER, NL, INDENT, NUMBER\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_sent.txt\", \"r\") as fp: \n",
    "    train_sent = fp.read().splitlines()\n",
    "with open(\"test_sent.txt\", \"r\") as fp:\n",
    "    test_sent = fp.read().splitlines()\n",
    "with open(\"full_corpus.txt\", \"r\") as fp:\n",
    "    full_corpus = fp.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import decoders, models, normalizers, pre_tokenizers, processors, trainers, Tokenizer\n",
    "tokenizer = Tokenizer(models.BPE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n', (0, 1)),\n",
       " ('Ġ,', (1, 3)),\n",
       " ('Ġ*', (3, 5)),\n",
       " ('Ġa', (5, 7)),\n",
       " ('Ġ=', (7, 9)),\n",
       " ('Ġmap', (9, 13)),\n",
       " ('Ġ(', (13, 15)),\n",
       " ('Ġint', (15, 19)),\n",
       " ('Ġ,', (19, 21)),\n",
       " ('Ġopen', (21, 26)),\n",
       " ('Ġ(', (26, 28)),\n",
       " ('Ġ<', (28, 30)),\n",
       " ('NUM', (30, 33)),\n",
       " ('_', (33, 34)),\n",
       " ('LIT', (34, 37)),\n",
       " (':', (37, 38)),\n",
       " ('0', (38, 39)),\n",
       " ('>', (39, 40)),\n",
       " ('Ġ)', (40, 42)),\n",
       " ('Ġ.', (42, 44)),\n",
       " ('Ġread', (44, 49)),\n",
       " ('Ġ(', (49, 51)),\n",
       " ('Ġ)', (51, 53)),\n",
       " ('Ġ.', (53, 55)),\n",
       " ('Ġsplit', (55, 61)),\n",
       " ('Ġ(', (61, 63)),\n",
       " ('Ġ)', (63, 65)),\n",
       " ('Ġ)', (65, 67)),\n",
       " ('Ċ', (67, 68))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(train_sent[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1000\n",
    "all_texts = [full_corpus[i : i+batch_size] for i in range(0, len(full_corpus), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterator():\n",
    "    for i in range(0, len(full_corpus), batch_size):\n",
    "        yield full_corpus[i : i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "literals = ['name', '\\\\n', 'U+0020', 'True', 'a', 'type', '__main__', 'id', '/', '.', 'w', 'utf-8', 'b', 'foo', '1', 'r', 'default', 'U+002C', '-', 'data', '0', '%s', 'x', 'blank', ':', 'value', 'max_length', 'c', '_', 'test', 'A', 'store_true', 'description', '*', 'null', 'title', 'y', 'U+002CU+0020', 'true', 'key', 'bar', '=', 'string', 'status', '2', 'rb', 'to', 'B', 'url', 'd', '\"', 'version', 'str', 'abc', 'int', 'GET', 'text', 'error', 'user', 'C', ')', 'wb', '\\\\t', '+', '\\\\\\\\', '#', '>', 'f', ';', 'path', 'ascii', 'POST', '?', '3', 'False', 'D', '|', 'label', 's', '(', 'message', \"'\", 'i', 'primary_key', '<', 'Meta', 'N', 'e', 'object_name', 'password', 'index', '..', 'code', 'class', 'username', 'F', 'size', '}', 'n', 'X', 'Y', 'file', 'z', '[', 'store', 'none', 'html', ']', 'utf8', 'p', 'strict', '\\\\r\\\\n', 'end', 'all', 'Name', 'state', 'produces', 'm', 't', 'I', 'result', 'bool', 'date', '{}', '\\\\x00', 'hello', 'start', 'left', 'email', 'ignore', 'S', '@', 'L', 'false', 'action', '{', 'related_name', 'time', 'count', 'v', '4', 'relu', 'win32', 'port', 'h', '#pop', 'source', 'Content-Type', 'application/json', '&', 'src', 'O', '-c', 'H', 'o', 'g', 'None', 'E', 'M', 'host', 'body', '%', 'info', 'image', 'float', 'root', 'l', 'T', 'replace', 'k', '\\\\ufffe', '100', '5', '$', 'right', 'content', 'q', 'args', 'u', 'address', '\\\\r', 'list', 'target', 'http', 'P', 'object', 'yes', '1.0', 'R', 'width', 'localhost', '127.0.0.1', 'train', '[?]', 'OK', 'location', 'filename', '!', 'success', 'input']\n",
    "tokens = [\"<|endoftext|>\",\"<EOL>\",\"<s>\",\"</s>\",\"<NUM_LIT>\",\"<STR_LIT>\"]\n",
    "trainer = trainers.BpeTrainer(vocab_size=25000, special_tokens=literals+tokens)\n",
    "tokenizer.train_from_iterator(batch_iterator(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)\n",
    "tokenizer.decoder = decoders.ByteLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "new_tokenizer = GPT2TokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('code-tokenizer-scratch/tokenizer_config.json',\n",
       " 'code-tokenizer-scratch/special_tokens_map.json',\n",
       " 'code-tokenizer-scratch/vocab.json',\n",
       " 'code-tokenizer-scratch/merges.txt',\n",
       " 'code-tokenizer-scratch/added_tokens.json',\n",
       " 'code-tokenizer-scratch/tokenizer.json')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.save_pretrained(\"code-tokenizer-scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorflowGPU",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
