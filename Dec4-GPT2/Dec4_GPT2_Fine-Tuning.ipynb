{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Flatten, TimeDistributed, Dropout, LSTMCell, RNN, Bidirectional, Concatenate, Layer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import pickle\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import requests\n",
    "import tarfile\n",
    "import glob\n",
    "\n",
    "import argparse\n",
    "from tokenize import tokenize, untokenize, COMMENT, STRING, NEWLINE, ENCODING, ENDMARKER, NL, INDENT, NUMBER\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_sent.txt\", \"r\") as fp: \n",
    "    train_sent = fp.read().splitlines() \n",
    "with open(\"test_sent.txt\", \"r\") as fp:\n",
    "    test_sent = fp.read().splitlines() \n",
    "with open(\"full_corpus.txt\", \"r\") as fp:\n",
    "    full_corpus = fp.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel,GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('code-tokenizer-scratch/',local_files_only=True)\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# model = TFGPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0,1,2,3], dim=0)\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# device_map = {0: [0, 1, 2, 3, 4, 5, 6, 7],1: [8, 9, 10, 11, 12, 13, 14, 15], 2: [16, 17, 18, 19, 20, 21, 22, 23], 3: [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]}\n",
    "# model.parallelize(device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 25000, max sequence length: 1000000000000000019884624838656\n"
     ]
    }
   ],
   "source": [
    "print('vocabulary size: %d, max sequence length: %d' % (tokenizer.vocab_size, tokenizer.model_max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 87, 306, 677]]), 'attention_mask': tensor([[1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(train_sent[0], return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [87, 306, 677], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(train_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'Ä =', 'Ä enumerate']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([87, 306, 677])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e = enumerate'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([87, 306, 677])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset,TrainingArguments,Trainer,pipeline,DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgoli/software/venv/tf1_gpu/lib/python3.7/site-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path='train_sent.txt',\n",
    "    overwrite_cache=True,\n",
    "    block_size=24)\n",
    "\n",
    "test_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path='test_sent.txt',\n",
    "    overwrite_cache=True,\n",
    "    block_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "!set os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = 'dec4_gpt', \n",
    "    overwrite_output_dir = True, \n",
    "#     per_device_train_batch_size = 64, \n",
    "#     per_device_eval_batch_size = 64, \n",
    "    learning_rate = 5e-4, \n",
    "    save_steps=1000,\n",
    "    logging_steps=3000,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "# Initializing the trainer class object that will do the training\n",
    "# here the data collator will generate the batch of size 64 of train and test data\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  7 00:24:09 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.42.01    Driver Version: 470.42.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    35W / 250W |   1933MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      4421      G   /usr/libexec/Xorg                  22MiB |\n",
      "|    0   N/A  N/A   2732944      C   .../venv/tf1_gpu/bin/python3     1907MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1592077\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 199010\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrohangoli\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/rohangoli/huggingface/runs/3e2aqt1n\" target=\"_blank\">dec4_gpt</a></strong> to <a href=\"https://wandb.ai/rohangoli/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='199010' max='199010' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [199010/199010 2:46:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.434000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.373900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.310300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.295400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>1.276200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>1.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>1.246100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.240400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>1.230700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>1.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>1.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>1.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.198700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>1.197500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>1.183400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>1.178300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>1.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.167800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>1.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>1.155100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>1.157200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>1.149400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.150400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>1.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81000</td>\n",
       "      <td>1.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>1.135100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87000</td>\n",
       "      <td>1.137700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.132100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93000</td>\n",
       "      <td>1.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>1.123500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99000</td>\n",
       "      <td>1.118900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>1.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>1.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111000</td>\n",
       "      <td>1.110200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114000</td>\n",
       "      <td>1.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117000</td>\n",
       "      <td>1.115700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.098900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123000</td>\n",
       "      <td>1.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126000</td>\n",
       "      <td>1.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129000</td>\n",
       "      <td>1.087000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132000</td>\n",
       "      <td>1.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138000</td>\n",
       "      <td>1.081100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141000</td>\n",
       "      <td>1.086500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144000</td>\n",
       "      <td>1.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147000</td>\n",
       "      <td>1.074500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.071100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153000</td>\n",
       "      <td>1.077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156000</td>\n",
       "      <td>1.072800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159000</td>\n",
       "      <td>1.074500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162000</td>\n",
       "      <td>1.067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165000</td>\n",
       "      <td>1.067400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168000</td>\n",
       "      <td>1.073100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171000</td>\n",
       "      <td>1.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174000</td>\n",
       "      <td>1.059500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177000</td>\n",
       "      <td>1.055700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180000</td>\n",
       "      <td>1.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183000</td>\n",
       "      <td>1.053500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186000</td>\n",
       "      <td>1.053600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189000</td>\n",
       "      <td>1.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192000</td>\n",
       "      <td>1.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195000</td>\n",
       "      <td>1.050700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198000</td>\n",
       "      <td>1.045700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to dec4_gpt/checkpoint-1000\n",
      "Configuration saved in dec4_gpt/checkpoint-1000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-1000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-133000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-2000\n",
      "Configuration saved in dec4_gpt/checkpoint-2000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-134000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-3000\n",
      "Configuration saved in dec4_gpt/checkpoint-3000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-4000\n",
      "Configuration saved in dec4_gpt/checkpoint-4000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-5000\n",
      "Configuration saved in dec4_gpt/checkpoint-5000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-6000\n",
      "Configuration saved in dec4_gpt/checkpoint-6000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-7000\n",
      "Configuration saved in dec4_gpt/checkpoint-7000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-8000\n",
      "Configuration saved in dec4_gpt/checkpoint-8000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-9000\n",
      "Configuration saved in dec4_gpt/checkpoint-9000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-9000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-10000\n",
      "Configuration saved in dec4_gpt/checkpoint-10000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-11000\n",
      "Configuration saved in dec4_gpt/checkpoint-11000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-12000\n",
      "Configuration saved in dec4_gpt/checkpoint-12000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-13000\n",
      "Configuration saved in dec4_gpt/checkpoint-13000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-13000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-14000\n",
      "Configuration saved in dec4_gpt/checkpoint-14000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-14000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-15000\n",
      "Configuration saved in dec4_gpt/checkpoint-15000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-15000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-13000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-16000\n",
      "Configuration saved in dec4_gpt/checkpoint-16000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-16000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-14000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-17000\n",
      "Configuration saved in dec4_gpt/checkpoint-17000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-17000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-15000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-18000\n",
      "Configuration saved in dec4_gpt/checkpoint-18000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-18000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-16000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-19000\n",
      "Configuration saved in dec4_gpt/checkpoint-19000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-19000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-17000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-20000\n",
      "Configuration saved in dec4_gpt/checkpoint-20000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-20000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-18000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-21000\n",
      "Configuration saved in dec4_gpt/checkpoint-21000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-21000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-19000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-22000\n",
      "Configuration saved in dec4_gpt/checkpoint-22000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-22000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-20000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-23000\n",
      "Configuration saved in dec4_gpt/checkpoint-23000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-23000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-21000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-24000\n",
      "Configuration saved in dec4_gpt/checkpoint-24000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-24000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-22000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-25000\n",
      "Configuration saved in dec4_gpt/checkpoint-25000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-25000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-23000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-26000\n",
      "Configuration saved in dec4_gpt/checkpoint-26000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-26000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-24000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-27000\n",
      "Configuration saved in dec4_gpt/checkpoint-27000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-27000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-25000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-28000\n",
      "Configuration saved in dec4_gpt/checkpoint-28000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-28000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-26000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-29000\n",
      "Configuration saved in dec4_gpt/checkpoint-29000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-29000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-27000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-30000\n",
      "Configuration saved in dec4_gpt/checkpoint-30000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-30000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-28000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-31000\n",
      "Configuration saved in dec4_gpt/checkpoint-31000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-31000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-29000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-32000\n",
      "Configuration saved in dec4_gpt/checkpoint-32000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-32000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-30000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-33000\n",
      "Configuration saved in dec4_gpt/checkpoint-33000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-33000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-31000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-34000\n",
      "Configuration saved in dec4_gpt/checkpoint-34000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-34000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-32000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-35000\n",
      "Configuration saved in dec4_gpt/checkpoint-35000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-35000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-33000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-36000\n",
      "Configuration saved in dec4_gpt/checkpoint-36000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-36000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-34000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-37000\n",
      "Configuration saved in dec4_gpt/checkpoint-37000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-37000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-35000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-38000\n",
      "Configuration saved in dec4_gpt/checkpoint-38000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-38000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-36000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-39000\n",
      "Configuration saved in dec4_gpt/checkpoint-39000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-39000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-37000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-40000\n",
      "Configuration saved in dec4_gpt/checkpoint-40000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-40000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-38000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-41000\n",
      "Configuration saved in dec4_gpt/checkpoint-41000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-41000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-39000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-42000\n",
      "Configuration saved in dec4_gpt/checkpoint-42000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-42000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-40000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-43000\n",
      "Configuration saved in dec4_gpt/checkpoint-43000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-43000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-41000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-44000\n",
      "Configuration saved in dec4_gpt/checkpoint-44000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-44000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-42000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-45000\n",
      "Configuration saved in dec4_gpt/checkpoint-45000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-45000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-43000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-46000\n",
      "Configuration saved in dec4_gpt/checkpoint-46000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-46000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-44000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-47000\n",
      "Configuration saved in dec4_gpt/checkpoint-47000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-47000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-45000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-48000\n",
      "Configuration saved in dec4_gpt/checkpoint-48000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-48000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-46000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-49000\n",
      "Configuration saved in dec4_gpt/checkpoint-49000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-49000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-47000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-50000\n",
      "Configuration saved in dec4_gpt/checkpoint-50000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-50000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-48000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-51000\n",
      "Configuration saved in dec4_gpt/checkpoint-51000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-51000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-49000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-52000\n",
      "Configuration saved in dec4_gpt/checkpoint-52000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-52000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-50000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-53000\n",
      "Configuration saved in dec4_gpt/checkpoint-53000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-53000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-51000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-54000\n",
      "Configuration saved in dec4_gpt/checkpoint-54000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-54000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-52000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-55000\n",
      "Configuration saved in dec4_gpt/checkpoint-55000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-55000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-53000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-56000\n",
      "Configuration saved in dec4_gpt/checkpoint-56000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-56000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-54000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-57000\n",
      "Configuration saved in dec4_gpt/checkpoint-57000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-57000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-55000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-58000\n",
      "Configuration saved in dec4_gpt/checkpoint-58000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-58000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-56000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-59000\n",
      "Configuration saved in dec4_gpt/checkpoint-59000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-59000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-57000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-60000\n",
      "Configuration saved in dec4_gpt/checkpoint-60000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-60000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-58000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-61000\n",
      "Configuration saved in dec4_gpt/checkpoint-61000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-61000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-59000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-62000\n",
      "Configuration saved in dec4_gpt/checkpoint-62000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-62000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-60000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-63000\n",
      "Configuration saved in dec4_gpt/checkpoint-63000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-63000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-61000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-64000\n",
      "Configuration saved in dec4_gpt/checkpoint-64000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-64000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-62000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-65000\n",
      "Configuration saved in dec4_gpt/checkpoint-65000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-65000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-63000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-66000\n",
      "Configuration saved in dec4_gpt/checkpoint-66000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-66000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-64000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-67000\n",
      "Configuration saved in dec4_gpt/checkpoint-67000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-67000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-65000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-68000\n",
      "Configuration saved in dec4_gpt/checkpoint-68000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-68000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-66000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-69000\n",
      "Configuration saved in dec4_gpt/checkpoint-69000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-69000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-67000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-70000\n",
      "Configuration saved in dec4_gpt/checkpoint-70000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-70000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-68000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-71000\n",
      "Configuration saved in dec4_gpt/checkpoint-71000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-71000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-69000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-72000\n",
      "Configuration saved in dec4_gpt/checkpoint-72000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-72000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-70000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-73000\n",
      "Configuration saved in dec4_gpt/checkpoint-73000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-73000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-71000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-74000\n",
      "Configuration saved in dec4_gpt/checkpoint-74000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-74000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-72000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-75000\n",
      "Configuration saved in dec4_gpt/checkpoint-75000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-75000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-73000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-76000\n",
      "Configuration saved in dec4_gpt/checkpoint-76000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-76000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-74000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-77000\n",
      "Configuration saved in dec4_gpt/checkpoint-77000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-77000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-75000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-78000\n",
      "Configuration saved in dec4_gpt/checkpoint-78000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-78000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-76000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-79000\n",
      "Configuration saved in dec4_gpt/checkpoint-79000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-79000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-77000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-80000\n",
      "Configuration saved in dec4_gpt/checkpoint-80000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-80000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-78000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-81000\n",
      "Configuration saved in dec4_gpt/checkpoint-81000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-81000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-79000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-82000\n",
      "Configuration saved in dec4_gpt/checkpoint-82000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-82000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-80000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-83000\n",
      "Configuration saved in dec4_gpt/checkpoint-83000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-83000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-81000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-84000\n",
      "Configuration saved in dec4_gpt/checkpoint-84000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-84000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-82000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-85000\n",
      "Configuration saved in dec4_gpt/checkpoint-85000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-85000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-83000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-86000\n",
      "Configuration saved in dec4_gpt/checkpoint-86000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-86000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-84000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-87000\n",
      "Configuration saved in dec4_gpt/checkpoint-87000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-87000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-85000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-88000\n",
      "Configuration saved in dec4_gpt/checkpoint-88000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-88000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-86000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-89000\n",
      "Configuration saved in dec4_gpt/checkpoint-89000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-89000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-87000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-90000\n",
      "Configuration saved in dec4_gpt/checkpoint-90000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-90000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-88000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-91000\n",
      "Configuration saved in dec4_gpt/checkpoint-91000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-91000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-89000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-92000\n",
      "Configuration saved in dec4_gpt/checkpoint-92000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-92000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-90000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-93000\n",
      "Configuration saved in dec4_gpt/checkpoint-93000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-93000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-91000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-94000\n",
      "Configuration saved in dec4_gpt/checkpoint-94000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-94000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-92000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-95000\n",
      "Configuration saved in dec4_gpt/checkpoint-95000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-95000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-93000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-96000\n",
      "Configuration saved in dec4_gpt/checkpoint-96000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-96000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-94000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-97000\n",
      "Configuration saved in dec4_gpt/checkpoint-97000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-97000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-95000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-98000\n",
      "Configuration saved in dec4_gpt/checkpoint-98000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-98000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-96000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-99000\n",
      "Configuration saved in dec4_gpt/checkpoint-99000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-99000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-97000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-100000\n",
      "Configuration saved in dec4_gpt/checkpoint-100000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-100000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-98000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-101000\n",
      "Configuration saved in dec4_gpt/checkpoint-101000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-101000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-99000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-102000\n",
      "Configuration saved in dec4_gpt/checkpoint-102000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-102000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-100000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-103000\n",
      "Configuration saved in dec4_gpt/checkpoint-103000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-103000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-101000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-104000\n",
      "Configuration saved in dec4_gpt/checkpoint-104000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-104000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-102000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-105000\n",
      "Configuration saved in dec4_gpt/checkpoint-105000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-105000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-103000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-106000\n",
      "Configuration saved in dec4_gpt/checkpoint-106000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-106000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-104000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-107000\n",
      "Configuration saved in dec4_gpt/checkpoint-107000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-107000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-105000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-108000\n",
      "Configuration saved in dec4_gpt/checkpoint-108000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-108000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-106000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-109000\n",
      "Configuration saved in dec4_gpt/checkpoint-109000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-109000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-107000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-110000\n",
      "Configuration saved in dec4_gpt/checkpoint-110000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-110000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-108000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-111000\n",
      "Configuration saved in dec4_gpt/checkpoint-111000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-111000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-109000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-112000\n",
      "Configuration saved in dec4_gpt/checkpoint-112000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-112000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-110000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-113000\n",
      "Configuration saved in dec4_gpt/checkpoint-113000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-113000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-111000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-114000\n",
      "Configuration saved in dec4_gpt/checkpoint-114000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-114000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-112000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-115000\n",
      "Configuration saved in dec4_gpt/checkpoint-115000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-115000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-113000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-116000\n",
      "Configuration saved in dec4_gpt/checkpoint-116000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-116000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-114000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-117000\n",
      "Configuration saved in dec4_gpt/checkpoint-117000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-117000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-115000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-118000\n",
      "Configuration saved in dec4_gpt/checkpoint-118000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-118000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-116000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-119000\n",
      "Configuration saved in dec4_gpt/checkpoint-119000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-119000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-117000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-120000\n",
      "Configuration saved in dec4_gpt/checkpoint-120000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-120000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-118000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-121000\n",
      "Configuration saved in dec4_gpt/checkpoint-121000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-121000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-119000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-122000\n",
      "Configuration saved in dec4_gpt/checkpoint-122000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-122000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-120000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-123000\n",
      "Configuration saved in dec4_gpt/checkpoint-123000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-123000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-121000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-124000\n",
      "Configuration saved in dec4_gpt/checkpoint-124000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-124000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-122000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-125000\n",
      "Configuration saved in dec4_gpt/checkpoint-125000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-125000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-123000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-126000\n",
      "Configuration saved in dec4_gpt/checkpoint-126000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-126000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-124000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-127000\n",
      "Configuration saved in dec4_gpt/checkpoint-127000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-127000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-125000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-128000\n",
      "Configuration saved in dec4_gpt/checkpoint-128000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-128000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-126000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-129000\n",
      "Configuration saved in dec4_gpt/checkpoint-129000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-129000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-127000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-130000\n",
      "Configuration saved in dec4_gpt/checkpoint-130000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-130000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-128000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-131000\n",
      "Configuration saved in dec4_gpt/checkpoint-131000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-131000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-129000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-132000\n",
      "Configuration saved in dec4_gpt/checkpoint-132000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-132000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-130000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-133000\n",
      "Configuration saved in dec4_gpt/checkpoint-133000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-133000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-131000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-134000\n",
      "Configuration saved in dec4_gpt/checkpoint-134000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-134000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-132000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-135000\n",
      "Configuration saved in dec4_gpt/checkpoint-135000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-135000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-133000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-136000\n",
      "Configuration saved in dec4_gpt/checkpoint-136000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-136000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-134000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-137000\n",
      "Configuration saved in dec4_gpt/checkpoint-137000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-137000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-135000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-138000\n",
      "Configuration saved in dec4_gpt/checkpoint-138000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-138000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-136000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-139000\n",
      "Configuration saved in dec4_gpt/checkpoint-139000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-139000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-137000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-140000\n",
      "Configuration saved in dec4_gpt/checkpoint-140000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-140000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-138000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-141000\n",
      "Configuration saved in dec4_gpt/checkpoint-141000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-141000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-139000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-142000\n",
      "Configuration saved in dec4_gpt/checkpoint-142000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-142000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-140000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-143000\n",
      "Configuration saved in dec4_gpt/checkpoint-143000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-143000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-141000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-144000\n",
      "Configuration saved in dec4_gpt/checkpoint-144000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-144000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-142000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-145000\n",
      "Configuration saved in dec4_gpt/checkpoint-145000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-145000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-143000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-146000\n",
      "Configuration saved in dec4_gpt/checkpoint-146000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-146000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-144000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-147000\n",
      "Configuration saved in dec4_gpt/checkpoint-147000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-147000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-145000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-148000\n",
      "Configuration saved in dec4_gpt/checkpoint-148000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-148000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-146000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-149000\n",
      "Configuration saved in dec4_gpt/checkpoint-149000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-149000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-147000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-150000\n",
      "Configuration saved in dec4_gpt/checkpoint-150000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-150000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-148000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-151000\n",
      "Configuration saved in dec4_gpt/checkpoint-151000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-151000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-149000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-152000\n",
      "Configuration saved in dec4_gpt/checkpoint-152000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-152000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-150000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-153000\n",
      "Configuration saved in dec4_gpt/checkpoint-153000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-153000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-151000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-154000\n",
      "Configuration saved in dec4_gpt/checkpoint-154000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-154000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-152000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-155000\n",
      "Configuration saved in dec4_gpt/checkpoint-155000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-155000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-153000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-156000\n",
      "Configuration saved in dec4_gpt/checkpoint-156000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-156000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-154000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-157000\n",
      "Configuration saved in dec4_gpt/checkpoint-157000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-157000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-155000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-158000\n",
      "Configuration saved in dec4_gpt/checkpoint-158000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-158000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-156000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-159000\n",
      "Configuration saved in dec4_gpt/checkpoint-159000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-159000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-157000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-160000\n",
      "Configuration saved in dec4_gpt/checkpoint-160000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-160000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-158000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-161000\n",
      "Configuration saved in dec4_gpt/checkpoint-161000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-161000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-159000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-162000\n",
      "Configuration saved in dec4_gpt/checkpoint-162000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-162000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-160000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-163000\n",
      "Configuration saved in dec4_gpt/checkpoint-163000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-163000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-161000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-164000\n",
      "Configuration saved in dec4_gpt/checkpoint-164000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-164000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-162000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-165000\n",
      "Configuration saved in dec4_gpt/checkpoint-165000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-165000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-163000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-166000\n",
      "Configuration saved in dec4_gpt/checkpoint-166000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-166000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-164000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-167000\n",
      "Configuration saved in dec4_gpt/checkpoint-167000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-167000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-165000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-168000\n",
      "Configuration saved in dec4_gpt/checkpoint-168000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-168000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-166000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-169000\n",
      "Configuration saved in dec4_gpt/checkpoint-169000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-169000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-167000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-170000\n",
      "Configuration saved in dec4_gpt/checkpoint-170000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-170000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-168000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-171000\n",
      "Configuration saved in dec4_gpt/checkpoint-171000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-171000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-169000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-172000\n",
      "Configuration saved in dec4_gpt/checkpoint-172000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-172000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-170000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-173000\n",
      "Configuration saved in dec4_gpt/checkpoint-173000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-173000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-171000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-174000\n",
      "Configuration saved in dec4_gpt/checkpoint-174000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-174000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-172000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-175000\n",
      "Configuration saved in dec4_gpt/checkpoint-175000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-175000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-173000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-176000\n",
      "Configuration saved in dec4_gpt/checkpoint-176000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-176000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-174000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-177000\n",
      "Configuration saved in dec4_gpt/checkpoint-177000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-177000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-175000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-178000\n",
      "Configuration saved in dec4_gpt/checkpoint-178000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-178000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-176000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-179000\n",
      "Configuration saved in dec4_gpt/checkpoint-179000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-179000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-177000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-180000\n",
      "Configuration saved in dec4_gpt/checkpoint-180000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-180000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-178000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-181000\n",
      "Configuration saved in dec4_gpt/checkpoint-181000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-181000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-179000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-182000\n",
      "Configuration saved in dec4_gpt/checkpoint-182000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-182000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-180000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-183000\n",
      "Configuration saved in dec4_gpt/checkpoint-183000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-183000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-181000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-184000\n",
      "Configuration saved in dec4_gpt/checkpoint-184000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-184000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-182000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-185000\n",
      "Configuration saved in dec4_gpt/checkpoint-185000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-185000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-183000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-186000\n",
      "Configuration saved in dec4_gpt/checkpoint-186000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-186000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-184000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-187000\n",
      "Configuration saved in dec4_gpt/checkpoint-187000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-187000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-185000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-188000\n",
      "Configuration saved in dec4_gpt/checkpoint-188000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-188000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-186000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-189000\n",
      "Configuration saved in dec4_gpt/checkpoint-189000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-189000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-187000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-190000\n",
      "Configuration saved in dec4_gpt/checkpoint-190000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-190000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-188000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-191000\n",
      "Configuration saved in dec4_gpt/checkpoint-191000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-191000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-189000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-192000\n",
      "Configuration saved in dec4_gpt/checkpoint-192000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-192000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-190000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-193000\n",
      "Configuration saved in dec4_gpt/checkpoint-193000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-193000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-191000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-194000\n",
      "Configuration saved in dec4_gpt/checkpoint-194000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-194000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-192000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-195000\n",
      "Configuration saved in dec4_gpt/checkpoint-195000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-195000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-193000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-196000\n",
      "Configuration saved in dec4_gpt/checkpoint-196000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-196000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-194000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-197000\n",
      "Configuration saved in dec4_gpt/checkpoint-197000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-197000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-195000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-198000\n",
      "Configuration saved in dec4_gpt/checkpoint-198000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-198000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-196000] due to args.save_total_limit\n",
      "Saving model checkpoint to dec4_gpt/checkpoint-199000\n",
      "Configuration saved in dec4_gpt/checkpoint-199000/config.json\n",
      "Model weights saved in dec4_gpt/checkpoint-199000/pytorch_model.bin\n",
      "Deleting older checkpoint [dec4_gpt/checkpoint-197000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=199010, training_loss=1.1492351851135778, metrics={'train_runtime': 10021.905, 'train_samples_per_second': 158.86, 'train_steps_per_second': 19.858, 'total_flos': 1.9499860988928e+16, 'train_loss': 1.1492351851135778, 'epoch': 1.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./saved_dec4_gpt_c\n",
      "Configuration saved in ./saved_dec4_gpt_c/config.json\n",
      "Model weights saved in ./saved_dec4_gpt_c/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('./saved_dec4_gpt_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 396534\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.239752173423767,\n",
       " 'eval_runtime': 477.3567,\n",
       " 'eval_samples_per_second': 830.687,\n",
       " 'eval_steps_per_second': 103.836,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating on Test data\n",
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file saved_dec4_gpt_c/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file saved_dec4_gpt_c/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file saved_dec4_gpt_c/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at saved_dec4_gpt_c.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', tokenizer=tokenizer, model='saved_dec4_gpt_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/home/rgoli/software/venv/tf1_gpu/lib/python3.7/site-packages/transformers/generation_utils.py:2142: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print ( solve ( )\n",
      "print ( ans )\n",
      "print ( \"<STR_\n"
     ]
    }
   ],
   "source": [
    "print(generator('print', max_length=5)[0]['generated_text'])\n",
    "print(generator('print', max_length=5,num_beams = 5)[0]['generated_text'])\n",
    "print(generator('print' , max_length=5 , do_sample=True,temperature = 0.7)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i in  :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i in  :\n",
      "for i in  :\n"
     ]
    }
   ],
   "source": [
    "print(generator('for i in ', max_length=5)[0]['generated_text'])\n",
    "print(generator('for i in ', max_length=5,num_beams = 5)[0]['generated_text'])\n",
    "print(generator('for i in ' , max_length=5 , do_sample=True,temperature = 0.7)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import import sys\n",
      "import fp\n"
     ]
    }
   ],
   "source": [
    "print(generator('import ', max_length=5)[0]['generated_text'])\n",
    "print(generator('import ', max_length=5,num_beams = 5)[0]['generated_text'])\n",
    "print(generator('import ' , max_length=5 , do_sample=True,temperature = 0.7)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  7 12:19:33 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.42.01    Driver Version: 470.42.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    34W / 250W |   4715MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      4421      G   /usr/libexec/Xorg                  22MiB |\n",
      "|    0   N/A  N/A   2732944      C   .../venv/tf1_gpu/bin/python3     4689MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file code-tokenizer-scratch/added_tokens.json. We won't load it.\n",
      "loading file code-tokenizer-scratch/vocab.json\n",
      "loading file code-tokenizer-scratch/merges.txt\n",
      "loading file None\n",
      "loading file code-tokenizer-scratch/special_tokens_map.json\n",
      "loading file code-tokenizer-scratch/tokenizer_config.json\n",
      "loading file code-tokenizer-scratch/tokenizer.json\n",
      "loading configuration file saved_dec4_gpt_c/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"saved_dec4_gpt_c\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file saved_dec4_gpt_c/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"saved_dec4_gpt_c\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file saved_dec4_gpt_c/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at saved_dec4_gpt_c.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print ( '<STR_\n",
      "print ( \"<STR_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print ( \"<STR_\n",
      "for i in cle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i in ations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i in ils\n",
      "import ï¿½ï¿½ï¿½\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import cessimport\n",
      "import ï¿½ã‚¯ã‚¯\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel,GPT2LMHeadModel\n",
    "from transformers import TextDataset,TrainingArguments,Trainer,pipeline,DataCollatorForLanguageModeling\n",
    "import torch\n",
    "\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('code-tokenizer-scratch/',local_files_only=True)\n",
    "generator = pipeline('text-generation', tokenizer=tokenizer, model='saved_dec4_gpt_c')\n",
    "\n",
    "print(generator('print', max_length=5)[0]['generated_text'])\n",
    "print(generator('print', max_length=5,num_beams = 5)[0]['generated_text'])\n",
    "print(generator('print' , max_length=5 , do_sample=True,temperature = 0.7)[0]['generated_text'])\n",
    "\n",
    "print(generator('for i in ', max_length=5)[0]['generated_text'])\n",
    "print(generator('for i in ', max_length=5,num_beams = 5)[0]['generated_text'])\n",
    "print(generator('for i in ' , max_length=5 , do_sample=True,temperature = 0.7)[0]['generated_text'])\n",
    "\n",
    "print(generator('import ', max_length=5)[0]['generated_text'])\n",
    "print(generator('import ', max_length=5,num_beams = 5)[0]['generated_text'])\n",
    "print(generator('import ' , max_length=5 , do_sample=True,temperature = 0.7)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file code-tokenizer-scratch/added_tokens.json. We won't load it.\n",
      "loading file code-tokenizer-scratch/vocab.json\n",
      "loading file code-tokenizer-scratch/merges.txt\n",
      "loading file code-tokenizer-scratch/tokenizer.json\n",
      "loading file None\n",
      "loading file code-tokenizer-scratch/special_tokens_map.json\n",
      "loading file code-tokenizer-scratch/tokenizer_config.json\n",
      "loading configuration file saved_dec4_gpt_c/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"saved_dec4_gpt_c\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file saved_dec4_gpt_c/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at saved_dec4_gpt_c.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i range_\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, top_k_top_p_filtering\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('code-tokenizer-scratch/',local_files_only=True)\n",
    "model = AutoModelForCausalLM.from_pretrained('saved_dec4_gpt_c', local_files_only=True)\n",
    "\n",
    "sequence = f\"for i range\"\n",
    "\n",
    "inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "# get logits of last hidden state\n",
    "next_token_logits = model(**inputs).logits[:, -1, :]\n",
    "\n",
    "# filter\n",
    "filtered_next_token_logits = top_k_top_p_filtering(next_token_logits, top_k=50, top_p=1.0)\n",
    "\n",
    "# sample\n",
    "probs = nn.functional.softmax(filtered_next_token_logits, dim=-1)\n",
    "next_token = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "generated = torch.cat([input_ids, next_token], dim=-1)\n",
    "\n",
    "resulting_string = tokenizer.decode(generated.tolist()[0])\n",
    "print(resulting_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorflowGPU",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
