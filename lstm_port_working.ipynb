{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Currently Loaded Modules:\n",
      "  1) anaconda3/5.1.0-gcc/8.3.1     4) cudnn/8.0.0.180-11.0-linux-x64-gcc/7.5.0\n",
      "  2) anaconda3/2019.10-gcc/8.3.1   5) openjdk/1.8.0_222-b10-gcc/8.3.1\n",
      "  3) cuda/11.0.3-gcc/7.5.0         6) hadoop/3.2.1-gcc/8.3.1\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!module list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Flatten, TimeDistributed, Dropout, LSTMCell, RNN, Bidirectional, Concatenate, Layer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import requests\n",
    "import tarfile\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "test  train\n",
      "\n",
      "data/train:\n",
      "C  C#  C++  D  Haskell\tJava  JavaScript  PHP  Python  Rust\n"
     ]
    }
   ],
   "source": [
    "file_name = \"Project_CodeNet_LangClass.tar.gz\"\n",
    "data_url = f\"https://dax-cdn.cdn.appdomain.cloud/dax-project-codenet/1.0.0/{file_name}\"\n",
    "\n",
    "# Download tar archive to local disk\n",
    "with open(file_name, \"wb\") as f:\n",
    "    f.write(requests.get(data_url).content)\n",
    "    \n",
    "# Extract contents of archive to local disk\n",
    "if os.path.exists(\"data\"):\n",
    "    shutil.rmtree(\"data\")    \n",
    "with tarfile.open(file_name) as tfile:\n",
    "    tfile.extractall()\n",
    "    \n",
    "!ls data data/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import re\n",
    "from tokenize import tokenize, untokenize, COMMENT, STRING, NEWLINE, ENCODING, ENDMARKER, NL, INDENT, NUMBER\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "lits = json.load(open(\"literals.json\"))\n",
    "\n",
    "def process_string(token, special_chars={\" \": \"U+0020\", \",\": \"U+002C\"}):\n",
    "    str_quote_options = [\"'''\", '\"\"\"', \"'\", '\"']\n",
    "    start_quote = \"\"\n",
    "    end_quote = \"\"\n",
    "    qualifier_regex = r\"^[a-z]+\"\n",
    "    qualifier_match = re.search(qualifier_regex, token)\n",
    "    # string qualifiers like 'r' for regex, 'f' for formatted string, 'b' for bytes, 'u' for unicode, etc (or combination of them)\n",
    "    qualifier = \"\" if not qualifier_match else qualifier_match[0]\n",
    "    # token string without qualifiers\n",
    "    token_string = re.sub(qualifier_regex, \"\", token)\n",
    "    # string literal without quotes\n",
    "    str_lit = token_string\n",
    "    for q in str_quote_options:\n",
    "        if token_string.startswith(q):\n",
    "            start_quote = q\n",
    "            str_lit = str_lit[len(q) :]\n",
    "            if token_string.endswith(q):\n",
    "                end_quote = q\n",
    "                str_lit = str_lit[: -len(q)]\n",
    "            break\n",
    "    # if start_quote in str_quote_options[:2]:\n",
    "    #     return \"\"\n",
    "    for sc in special_chars:\n",
    "        str_lit = str_lit.replace(sc, special_chars[sc])\n",
    "    return (\n",
    "        f\"{qualifier}{start_quote}<STR_LIT:{str_lit}>{end_quote}\"\n",
    "        if str_lit in lits['str']\n",
    "        else f\"{qualifier}{start_quote}<STR_LIT>{end_quote}\"\n",
    "    )\n",
    "\n",
    "def py_tokenize(file_type):\n",
    "    file_paths = glob.glob(os.path.join(os.getcwd(),\"data/\"+file_type+\"/Python\",\"*.*\"))\n",
    "    wf = open(os.path.join(os.getcwd(), f\"{file_type}.txt\"), 'w')\n",
    "    local_corpus = []\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            code = open(path).read()\n",
    "            token_gen = tokenize(BytesIO(bytes(code, \"utf8\")).readline)\n",
    "            out_tokens = []\n",
    "            prev_eol = False\n",
    "            for toknum, tokval, _, _, _ in token_gen:\n",
    "                tokval = \" \".join(tokval.split())\n",
    "                if toknum == STRING:\n",
    "                    add_token = process_string(tokval)\n",
    "                    out_tokens.append(add_token)\n",
    "                    prev_eol = False\n",
    "                elif toknum == NUMBER:\n",
    "                    if tokval in lits['num']:\n",
    "                        out_tokens.append(f\"<NUM_LIT:{tokval}>\")\n",
    "                    else:\n",
    "                        out_tokens.append(f\"<NUM_LIT>\")\n",
    "                    prev_eol = False\n",
    "                elif toknum in [NEWLINE, NL]:\n",
    "                    if not prev_eol:\n",
    "                        out_tokens.append(\"<EOL>\")\n",
    "                        prev_eol = True\n",
    "                elif toknum in [COMMENT, INDENT, ENCODING, ENDMARKER] or len(tokval) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    out_tokens.append(tokval)\n",
    "                    prev_eol = False\n",
    "            if out_tokens[0] == \"<EOL>\":\n",
    "                out_tokens = out_tokens[1:]\n",
    "            if out_tokens[-1] == \"<EOL>\":\n",
    "                out_tokens = out_tokens[:-1]\n",
    "        except Exception:\n",
    "            out_tokens = []\n",
    "#         local_corpus.extend((\" \".join(out_tokens)).split('<EOL>'))\n",
    "#         out_tokens = [\"<s>\"] + out_tokens + [\"</s>\"]\n",
    "        out = \" \".join(out_tokens)\n",
    "        local_corpus.append(out)\n",
    "        wf.write(out+\"\\n\")\n",
    "    print(f\"{file_type}: are done\")\n",
    "    wf.close()\n",
    "    return local_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: are done\n",
      "['arr = [ <NUM_LIT:0> ] * <NUM_LIT:100> ', ' while True : ', ' try : ', ' x , y , s = map ( int , input ( ) . split ( \"<STR_LIT:U+002C>\" ) ) ', ' if s == <NUM_LIT:3> : ', ' if x <= <NUM_LIT:7> : ', ' arr [ <NUM_LIT:10> * y + x + <NUM_LIT:2> ] += <NUM_LIT:1> ', ' if x >= <NUM_LIT:2> : ', ' arr [ <NUM_LIT:10> * y + x - <NUM_LIT:2> ] += <NUM_LIT:1> ', ' if y <= <NUM_LIT:7> : ', ' arr [ <NUM_LIT:10> * y + x + <NUM_LIT:20> ] += <NUM_LIT:1> ', ' if y >= <NUM_LIT:2> : ', ' arr [ <NUM_LIT:10> * y + x - <NUM_LIT:20> ] += <NUM_LIT:1> ', ' if s >= <NUM_LIT:2> : ', ' if x != <NUM_LIT:9> and y != <NUM_LIT:9> : ', ' arr [ <NUM_LIT:10> * y + x + <NUM_LIT:11> ] += <NUM_LIT:1> ', ' if x != <NUM_LIT:9> and y != <NUM_LIT:0> : ', ' arr [ <NUM_LIT:10> * y + x - <NUM_LIT:9> ] += <NUM_LIT:1> ', ' if x != <NUM_LIT:0> and y != <NUM_LIT:0> : ', ' arr [ <NUM_LIT:10> * y + x - <NUM_LIT:11> ] += <NUM_LIT:1> ']\n",
      "3815\n"
     ]
    }
   ],
   "source": [
    "corpus = py_tokenize(\"train\")\n",
    "corpus_new = []\n",
    "for code in corpus:\n",
    "    corpus_new.extend(code.split('<EOL>'))\n",
    "print(corpus_new[0:20])\n",
    "print(len(corpus_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr', '=', '[', '<NUM_LIT:0>', ']', '*', '<NUM_LIT:100>', '<EOL>', 'while', 'True', ':', '<EOL>', 'try', ':', '<EOL>', 'x', ',', 'y', ',', 's', '=', 'map', '(', 'int', ',', 'input', '(', ')', '.', 'split', '(', '\"<STR_LIT:U+002C>\"', ')', ')', '<EOL>', 'if', 's', '==', '<NUM_LIT:3>', ':', '<EOL>', 'if', 'x', '<=', '<NUM_LIT:7>', ':', '<EOL>', 'arr', '[', '<NUM_LIT:10>', '*', 'y', '+', 'x', '+', '<NUM_LIT:2>', ']', '+=', '<NUM_LIT:1>', '<EOL>', 'if', 'x', '>=', '<NUM_LIT:2>', ':', '<EOL>', 'arr', '[', '<NUM_LIT:10>', '*', 'y', '+', 'x', '-', '<NUM_LIT:2>', ']', '+=', '<NUM_LIT:1>', '<EOL>', 'if', 'y', '<=', '<NUM_LIT:7>', ':', '<EOL>', 'arr', '[', '<NUM_LIT:10>', '*', 'y', '+', 'x', '+', '<NUM_LIT:20>', ']', '+=', '<NUM_LIT:1>', '<EOL>', 'if', 'y']\n"
     ]
    }
   ],
   "source": [
    "full_corpus_tokens = ''.join(corpus).split()\n",
    "print(full_corpus_tokens[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['arr', '=', '[', '<NUM_LIT:0>'], ['=', '[', '<NUM_LIT:0>', ']'], ['[', '<NUM_LIT:0>', ']', '*'], ['<NUM_LIT:0>', ']', '*', '<NUM_LIT:100>'], [']', '*', '<NUM_LIT:100>', '<EOL>'], ['*', '<NUM_LIT:100>', '<EOL>', 'while'], ['<NUM_LIT:100>', '<EOL>', 'while', 'True'], ['<EOL>', 'while', 'True', ':'], ['while', 'True', ':', '<EOL>'], ['True', ':', '<EOL>', 'try']]\n"
     ]
    }
   ],
   "source": [
    "train_len = 3+1\n",
    "text_sequences = []\n",
    "for i in range(train_len,len(full_corpus_tokens)):\n",
    "    seq = full_corpus_tokens[i-train_len:i]\n",
    "    text_sequences.append(seq)\n",
    "sequences = {}\n",
    "count = 1\n",
    "for i in range(len(full_corpus_tokens)):\n",
    "    if full_corpus_tokens[i] not in sequences:\n",
    "        sequences[full_corpus_tokens[i]] = count\n",
    "        count += 1\n",
    "print(text_sequences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(text_sequences)\n",
    "sequences = tokenizer.texts_to_sequences(text_sequences) \n",
    "\n",
    "#Collecting some information   \n",
    "vocabulary_size = len(tokenizer.word_counts)+1\n",
    "\n",
    "n_sequences = np.empty([len(sequences),train_len], dtype='int32')\n",
    "for i in range(len(sequences)):\n",
    "    n_sequences[i] = sequences[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40546, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs = n_sequences[:,:-1]\n",
    "train_targets = n_sequences[:,-1]\n",
    "train_targets = to_categorical(train_targets, num_classes=vocabulary_size)\n",
    "seq_len = train_inputs.shape[1]\n",
    "train_inputs.shape\n",
    "#print(train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 3, 3)              2322      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 3, 50)             10800     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 774)               39474     \n",
      "=================================================================\n",
      "Total params: 75,346\n",
      "Trainable params: 75,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "1268/1268 [==============================] - 9s 5ms/step - loss: 4.6838 - accuracy: 0.0875\n",
      "Epoch 2/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 3.8811 - accuracy: 0.1582\n",
      "Epoch 3/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 3.1094 - accuracy: 0.2894\n",
      "Epoch 4/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 2.8118 - accuracy: 0.3442\n",
      "Epoch 5/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 2.6609 - accuracy: 0.3762\n",
      "Epoch 6/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 2.5458 - accuracy: 0.3879\n",
      "Epoch 7/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 2.4180 - accuracy: 0.4184\n",
      "Epoch 8/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 2.3120 - accuracy: 0.4337\n",
      "Epoch 9/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 2.2332 - accuracy: 0.4498\n",
      "Epoch 10/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 2.1394 - accuracy: 0.4712\n",
      "Epoch 11/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 2.0942 - accuracy: 0.4772\n",
      "Epoch 12/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 2.0505 - accuracy: 0.4793\n",
      "Epoch 13/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.9898 - accuracy: 0.4909\n",
      "Epoch 14/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.9404 - accuracy: 0.4995\n",
      "Epoch 15/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.9227 - accuracy: 0.5063\n",
      "Epoch 16/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.8647 - accuracy: 0.5144\n",
      "Epoch 17/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.8389 - accuracy: 0.5204\n",
      "Epoch 18/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.8132 - accuracy: 0.5217\n",
      "Epoch 19/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.7970 - accuracy: 0.5238\n",
      "Epoch 20/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.7601 - accuracy: 0.5336\n",
      "Epoch 21/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.7335 - accuracy: 0.5347\n",
      "Epoch 22/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.7337 - accuracy: 0.5352\n",
      "Epoch 23/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.7004 - accuracy: 0.5410\n",
      "Epoch 24/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.6682 - accuracy: 0.5488\n",
      "Epoch 25/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.6584 - accuracy: 0.5463\n",
      "Epoch 26/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.6449 - accuracy: 0.5530\n",
      "Epoch 27/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.6384 - accuracy: 0.5535\n",
      "Epoch 28/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.6034 - accuracy: 0.5576\n",
      "Epoch 29/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.5884 - accuracy: 0.5615\n",
      "Epoch 30/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.5673 - accuracy: 0.5701\n",
      "Epoch 31/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.5780 - accuracy: 0.5628\n",
      "Epoch 32/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.5487 - accuracy: 0.5699\n",
      "Epoch 33/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.5382 - accuracy: 0.5716\n",
      "Epoch 34/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.5249 - accuracy: 0.5773\n",
      "Epoch 35/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.5105 - accuracy: 0.5764\n",
      "Epoch 36/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.5072 - accuracy: 0.5760\n",
      "Epoch 37/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.4950 - accuracy: 0.5800\n",
      "Epoch 38/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.4776 - accuracy: 0.5829\n",
      "Epoch 39/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.4902 - accuracy: 0.5797\n",
      "Epoch 40/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.4651 - accuracy: 0.5834\n",
      "Epoch 41/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.4658 - accuracy: 0.5842\n",
      "Epoch 42/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.4394 - accuracy: 0.5898\n",
      "Epoch 43/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.4297 - accuracy: 0.5938\n",
      "Epoch 44/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.4210 - accuracy: 0.5984\n",
      "Epoch 45/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.4237 - accuracy: 0.5895\n",
      "Epoch 46/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.4159 - accuracy: 0.5913\n",
      "Epoch 47/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.4062 - accuracy: 0.5959\n",
      "Epoch 48/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.3903 - accuracy: 0.5991\n",
      "Epoch 49/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.3909 - accuracy: 0.6021\n",
      "Epoch 50/50\n",
      "1268/1268 [==============================] - 6s 5ms/step - loss: 1.3765 - accuracy: 0.6040\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "#model = load_model(\"mymodel.h5\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, seq_len, input_length=seq_len))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(vocabulary_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_inputs,train_targets,epochs=50,verbose=1)\n",
    "model.save(\"mymodel_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm_port.h5')\n",
    "model = load_model('lstm_port.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " if x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word suggestion: ['+', 'in', '==']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " for i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word suggestion: ['in', ',', '(']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " for i,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word suggestion: ['j', 'i', 'x']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " for i in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word suggestion: ['range', 'xrange', 'sys']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " for i in range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word suggestion: ['(', '-', '<num_lit:2>']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " import\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word suggestion: [\"'<str_lit>'\", '[', 'input']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " import math\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word suggestion: ['.', ',', ')']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " import math.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word suggestion: [\"'<str_lit>'\", '[', 'input']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word suggestion: ['.', ',', ':']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " import sys,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word suggestion: [\"'<str_lit>'\", '[', 'input']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " return\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word suggestion: ['[', 'int', 'sys']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " stop\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "input_text = input().strip().lower()\n",
    "while(input_text != 'stop'):\n",
    "    encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "    pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "#     print(encoded_text, pad_encoded)\n",
    "    predictions = []\n",
    "    for i in (model.predict(pad_encoded)[0]).argsort()[-3:][::-1]:\n",
    "        pred_word = tokenizer.index_word[i]\n",
    "        predictions.append(pred_word)\n",
    "    print(\"Next word suggestion:\",predictions)\n",
    "    input_text = input().strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorflowGPU",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
